---
title: "PPCA0026 - Tarefa 5: Métodos de Monte Carlo e MCMC"
subtitle: "Baseado em 'Statistical Computing with R' de Maria Rizzo"
author: "Sílvio Ferreira Gomes Júnior"
date: "2025-08-08"
format:
  html:
    embed-resources: true
    toc: true
    toc-depth: 3
    theme: cosmo
    code-fold: show
    code-tools: true
---

## Introdução

Este arquivo serve como seu template de resposta. Preencha as seções marcadas com seu código R, as saídas geradas, e suas análises textuais.

```{r setup, include=FALSE}
# Carregue todos os pacotes que você usará aqui
library(tidyverse)
library(mvtnorm) # Pode ser útil para o Problema 3
#library(httpgd)
```

---

## Problema 1: Integração por Monte Carlo e Variáveis Antitéticas (Capítulo 7)

Neste problema, vamos estimar o valor de uma integral definida e ver como uma técnica de amostragem mais inteligente pode melhorar a precisão da nossa estimativa.

**Tarefa (baseada no Exercício 7.5 de Rizzo):**

O nosso objetivo é estimar o valor de $I = \int_0^1 \frac{e^{-x}}{1+x^2} dx$.



### 1.1 Estimação com Monte Carlo Padrão

```{r prob1a_standard_mc}
# Defina a função a ser integrada
f <- function(x) {
  # ... seu código aqui ...
  exp(-x) / (1 + x^2)
}

m <- 10000 # Número de amostras
set.seed(123)

# Gere as amostras e calcule a estimativa
x <- runif(m)
fx <- f(x)
mc_estimate <- mean(fx)
mc_var <- var(fx) / m
mc_se <- sqrt(mc_var)

# Reporte a estimativa e a variância empírica


cat("A estimativa da integral é: ", round(mc_estimate, 6), "\n")
cat("A estimativa para a variância empírica é: ", round(mc_var, 8), "\n")
cat("A estimativa para o erro padrão é: $", round(mc_se , 6), "\n")

# ...
```

### 1.2 Estimação com Variáveis Antitéticas

```{r prob1b_antithetic_mc}
# Use m/2 amostras para criar m pontos de avaliação
set.seed(123)

m2 <- m / 2
u <- runif(m2)


# Gere as amostras e calcule a estimativa antitética
amostra_antietica <- (f(u) + f(1 - u)) / 2
estimativa_antietica <- mean(amostra_antietica)
variancia_antietica <- var(amostra_antietica) /m2
antietica_se <- sqrt(variancia_antietica)

# Reporte a estimativa e a variância empírica
cat("A estimativa da integral (antitética) é: ", round(estimativa_antietica, 4), "\n")
cat("A estimativa para a variância empírica (antitética) é: ", round(variancia_antietica, 8), "\n")
cat("A estimativa para o erro padrão (antitética) é: $", round(antietica_se , 6), "\n")

```

### 1.3 Análise e Comparação


| Método                        | Estimativa da Integral | Erro Padrão Empírico |
|-------------------------------|------------------------|--------------------|
| Monte Carlo Padrão            |0,53|0,002438|
| Método da estimativa Antitética   |0,52|0,000468|

**Redução percentual do erro padrão:** A redução foi de, aproximadamente, 80% (em relação à variância, o percentual seria de aproximadamente 97%)

Como podemos observar, o método da Estimatíva Antiética reduziu o erro padrão em aproximadamente 80% sendo, assim, superior ao método de Monte Carlo.

---

## Problema 2: Amostragem por Rejeição (Rejection Sampling) (Capítulo 6)

O objetivo é gerar amostras de uma distribuição `Beta(2, 2)` usando o algoritmo de amostragem por rejeição.

### 2.1 Encontrando a Constante `c`

```{r prob2a_find_c}
#Este problema introduz a lógica de aceitar/rejeitar amostras, que é fundamental para o MCMC. 
#O objetivo é gerar amostras de uma distribuição alvo usando uma distribuição “envelope” mais simples.

# A distribuição alvo é f(x) = dbeta(x, 2, 2)
# A distribuição envelope é g(x) = dunif(x, 0, 1) = 1
# Encontre o valor máximo da razão f(x)/g(x) no intervalo [0, 1].
# Você pode fazer isso analiticamente ou numericamente.

# Definindo a distribuição alvo:
f <- function(x) dbeta(x, 2, 2)
# Definindo a distribuição envelope
g <- function(x) dunif(x, 0, 1) 

# Encontrando o valor máximo de f(x)/g(x) no intervalo [0, 1]

grid <- seq(0, 1, length.out = 10001)
divisao <- f(grid) / g(grid)
c <- max(divisao)

cat("A estimativa de C é: ", round(c, 4), "\n")

```

**Análise da Tarefa 2.1:**

Após definir as duas funções de densidade, conforme solicitado, utilizei a dica de maximização da divisão de $\frac{f(x)}{g(x)}$. Enfim, apliquei essa função de divisão a um grid de valores entre 0 e 1 (10001)

### 2.2 Implementando o Amostrador por Rejeição

```{r prob2b_rejection_sampler}
# Escreva uma função que implementa o algoritmo de amostragem por rejeição.
# A função deve aceitar n (o número de amostras a gerar) e c como argumentos.
rejection_sampler_beta <- function(n, c) {

  # Definindo a distribuição alvo:
  f <- function(x) dbeta(x, 2, 2)
  # Definindo a distribuição envelope
  g <- function(x) dunif(x, 0, 1) 

  amostras_aceitas <- numeric(n)
  total_propostas <- 0
  aceitas <- 0
  
  # Loop até obter n amostras aceitas
  while(aceitas < n) {
    y <- runif(1, 0, 1) 
    u <- runif(1, 0, 1)
    
    #Tirei essa regra do livro
    if (u < f(y) / (c * g(y))) {
      aceitas <- aceitas + 1
      amostras_aceitas[aceitas] <- y
    }

    total_propostas <- total_propostas + 1
  }
  
  # Calcular taxa de aceitação
  taxa_aceitacao <- aceitas / total_propostas
  
  # Retornar lista com amostras e informações do processo
  return(list(
    amostras = amostras_aceitas,
    taxa_aceitacao = taxa_aceitacao,
    total_propostas = total_propostas
  ))
}

# Gere 2000 amostras usando sua função
set.seed(123)
resultado_beta <- rejection_sampler_beta(2000, 1.5)
amostras_beta <- resultado_beta$amostras

```


### 2.3 Verificação dos Resultados

```{r prob2c_verification}
# Crie um histograma das suas amostras geradas
# Sobreponha a curva de densidade teórica da Beta(2, 2) para verificar

# Organize as amostras em um data frame
df_beta <- data.frame(amostra = amostras_beta)

# Crie o histograma com ggplot2 e sobreponha a densidade teórica
ggplot(df_beta, aes(x = amostra)) +
  geom_histogram(aes(y = ..density..), bins = 30, fill = "lightblue", color = "white") +
  stat_function(fun = function(x) dbeta(x, 2, 2), color = "red", size = 1.2) +
  labs(title = "Amostragem por Rejeição: Beta(2,2)",
       x = "x", y = "Densidade") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5)) +
  annotate("text", x = 0.8, y = 2.2, label = "Densidade Teórica Beta(2,2)", color = "red", size = 4)

# Reporte a taxa de aceitação do seu amostrador

cat("Taxa de aceitação:", round(resultado_beta$taxa_aceitacao, 4), "\n")
cat("Total de propostas:", resultado_beta$total_propostas, "\n")

```

**Análise da Tarefa 2.3:**

Uma taxa de aceitação de aproximadamente 0,66 significa que, em média, aproximadamente 2 em cada 3 amostras propostas pelo algoritmo foram aceitas para fazer parte do nosso conjunto final de possíveis valores. Como, de acordo com o livro citado, a taxa de aceitação teórica máxima é de $\frac{1}{c}$, então 1/1.5 = 0,666, ou seja, nossa taxa chegou ao limite.

---

## Problema 3: O Algoritmo de Metropolis-Hastings (Capítulo 9)

O objetivo é gerar amostras de uma distribuição Normal Bivariada com alta correlação ($\rho=0.9$) usando um amostrador de Metropolis-Hastings de passeio aleatório.

### 3.1 Implementando o Amostrador

```{r prob3a_metropolis_hastings}
# Defina a densidade alvo (ou seu logaritmo)
# A média é (0, 0) e a matriz de covariância tem 1s na diagonal e 0.9 fora dela.
# A função `mvtnorm::dmvnorm` pode ser útil para calcular a densidade.

mu <- c(0, 0)
Sigma <- matrix(c(1, 0.9, 0.9, 1), nrow = 2)
log_alvo <- function(x) {
  mvtnorm::dmvnorm(x, mean = mu, sigma = Sigma, log = TRUE)
}

# Implemente a função do amostrador de Metropolis-Hastings
metropolis_bvn <- function(n_iter, sigma_prop) {
  # n_iter: número de iterações
  # sigma_prop: desvio padrão da proposta (assumido igual para ambas as dimensões)
  
  # 1. Inicializar a cadeia
  cadeia_mk <- matrix(0, nrow = n_iter, ncol = 2)
  estado_atual <- c(0, 0)  # Ponto inicial (0, 0)
  cadeia_mk[1, ] <- estado_atual
  
  # Contador de aceitações
  n_aceito <- 0
  
  # Matriz de covariância para a proposta (diagonal)
  Sigma_prop <- diag(c(sigma_prop^2, sigma_prop^2))
  
  # 2. Loop pelas iterações
  for (i in 2:n_iter) {
    
    # 3. Propor um novo ponto a partir da distribuição de proposta
    # Proposta Normal Bivariada centrada no ponto atual
    proposta <- rnorm(2, mean = estado_atual, sd = sigma_prop)
    proposta <- as.vector(proposta)
    
    # 4. Calcular a razão de aceitação
    # r = f(proposto) / f(atual)
    log_r <- log_alvo(proposta) - log_alvo(estado_atual)
    r <- exp(log_r)
    
    # 5. Aceitar o ponto proposto com probabilidade min(1, r)
    if (runif(1) < min(1, r)) {
      # Se rejeitado, o próximo ponto da cadeia é o mesmo que o ponto atual
      estado_atual <- proposta
      n_aceito <- n_aceito + 1
    }
    # Caso contrário, permanece no estado atual (estado_atual inalterado)
    
    # 6. Armazenar o ponto na cadeia
    cadeia_mk[i, ] <- estado_atual
  }
  
  # 7. Calcular taxa de aceitação
  tx_aceita <- n_aceito / (n_iter - 1)
  
  # Retornar resultados
  return(list(
    cadeia_mk = cadeia_mk,
    tx_aceita = tx_aceita,
    n_aceito = n_aceito,
    n_iter = n_iter
  ))
}

# Execute o amostrador
set.seed(123)
# Teste com diferentes valores de sigma_prop para ver o efeito na taxa de aceitação
resultado_mcmc <- metropolis_bvn(n_iter = 10000, sigma_prop = 1.0)
cadeia_mcmc <- resultado_mcmc$cadeia_mk

```

```{r prob3a_metropolis_hastings2}

result_mcmc_sigma05 <- metropolis_bvn(n_iter = 100000, sigma_prop = 0.5)

result_mcmc_sigma2 <- metropolis_bvn(n_iter = 10000, sigma_prop = 2)


```



### 3.2 Análise da Saída

```{r prob3b_analysis}

# Reporte a taxa de aceitação
cat("Taxa de aceitação:", round(resultado_mcmc$tx_aceita, 4), "\n")
cat("Número de amostras aceitas:", resultado_mcmc$n_aceito, "\n")
cat("Número total de iterações:", resultado_mcmc$n_iter, "\n")


# Descarte o burn-in
burn_in <- 2000
cadeia_burnin <- cadeia_mcmc[-burn_in,]

# Crie os trace plots para cada uma das duas variáveis

df_cadeia <- as.data.frame(cadeia_mcmc)
colnames(df_cadeia) <- c("X1", "X2")
df_cadeia$iter <- 1:nrow(df_cadeia)


library(patchwork)

# Trace plots lado a lado usando patchwork
p1 <- ggplot(df_cadeia, aes(x = iter, y = X1)) +
  geom_line(color = "blue") +
  labs(title = "Trace plot para X1", x = "Iteração", y = "X1") +
  theme_minimal()

p2 <- ggplot(df_cadeia, aes(x = iter, y = X2)) +
  geom_line(color = "darkgreen") +
  labs(title = "Trace plot para X2", x = "Iteração", y = "X2") +
  theme_minimal()

# Exibir os dois gráficos em um grid
p1 / p2


# Crie o scatter plot das amostras geradas
# Scatter plot das amostras após o burn-in
df_cadeia_burnin <- as.data.frame(cadeia_burnin)
colnames(df_cadeia_burnin) <- c("X1", "X2")


amostras_teoricas <- mvtnorm::rmvnorm(1e4, mean = mu, sigma = Sigma)
df_teoricas <- as.data.frame(amostras_teoricas)
colnames(df_teoricas) <- c("X1", "X2")


ggplot(df_cadeia_burnin, aes(x = X1, y = X2)) +
  geom_point(alpha = 0.3, color = "purple", size = 1) +
  stat_density_2d(aes(fill = ..level..), geom = "polygon", alpha = 0.2, color = NA) +
  labs(title = "Scatter plot das amostras MCMC (após burn-in)",
       x = "X1", y = "X2") +
  theme_minimal()
# Verificação Visual: Sobreponha as linhas de contorno teóricas
# Sobrepondo as linhas de contorno teóricas da distribuição alvo
ggplot(df_cadeia_burnin, aes(x = X1, y = X2)) +
  geom_point(alpha = 0.3, color = "purple", size = 1) +
  stat_density_2d(aes(fill = ..level..), geom = "polygon", alpha = 0.2, color = NA) +
  stat_density_2d(
    data = df_teoricas,
    aes(x = X1, y = X2),
    color = "red", size = 1, bins = 6, geom = "density_2d"
  ) +
  labs(title = "Scatter plot das amostras MCMC (após burn-in) com contornos teóricos",
       subtitle = "Roxo: Amostras MCMC | Vermelho: Contornos teóricos",
       x = "X1", y = "X2") +
  theme_minimal()

  # Gráfico de autocorrelação para X1 e X2 após o burn-in
  acf_x1 <- acf(df_cadeia_burnin$X1, plot = FALSE)
  acf_x2 <- acf(df_cadeia_burnin$X2, plot = FALSE)

  par(mfrow = c(2, 1))
  plot(acf_x1, main = "Autocorrelação de X1 (após burn-in)")
  plot(acf_x2, main = "Autocorrelação de X2 (após burn-in)")
  par(mfrow = c(1, 1))

  print("Podemos perceber que existe uma grande autocorrelação em ambas as variáveis por conta da simulação via cadeia de markov. A ideia é realizar uma amostragem de valores")
  print("No presente caso, decidiu-se por amostrar a cada 50 valores")

# Amostragem sistemática opcional para reduzir autocorrelação
  cadeia_final <- cadeia_burnin[seq(1, nrow(cadeia_burnin), by = 50), ]
  cadeia_final<-as.data.frame(cadeia_final)
  colnames(cadeia_final) <- c("X1", "X2")
  cadeia_final$iter <- 1:nrow(cadeia_final)
  

p11 <- ggplot(cadeia_final, aes(x = iter, y = X1)) +
  geom_line(color = "blue") +
  labs(title = "Trace plot para X1 (amostrado)", x = "Iteração", y = "X1") +
  theme_minimal()

p21 <- ggplot(cadeia_final, aes(x = iter, y = X2)) +
  geom_line(color = "darkgreen") +
  labs(title = "Trace plot para X2 (amostrado)", x = "Iteração", y = "X2") +
  theme_minimal()

# Exibir os dois gráficos em um grid
p11 / p21

amostras_teoricas2 <- mvtnorm::rmvnorm(length(cadeia_final), mean = mu, sigma = Sigma)
df_teoricas2 <- as.data.frame(amostras_teoricas2)
colnames(df_teoricas2) <- c("X1", "X2")

ggplot(cadeia_final, aes(x = X1, y = X2)) +
  geom_point(alpha = 0.3, color = "purple", size = 1) +
  stat_density_2d(aes(fill = ..level..), geom = "polygon", alpha = 0.2, color = NA) +
  labs(title = "Scatter plot das amostras MCMC (após burn-in)",
       x = "X1", y = "X2") +
  theme_minimal()

```

Realizando a análise para um $\sigma = 0.5$.


```{r prob3b_analysis2}

# CRIANDO UMA FUNÇÃO QUE GERA OS RESULTADOS PASSADOS MAS ESCOLHENDO VARIANCIAS DIFERENTES

library(patchwork)
# Função para analisar e plotar resultados de uma simulação Metropolis-Hastings,
# incluindo gráficos de nível e análise após amostragem sistemática (thinning)
analisar_mcmc_com_thin <- function(resultado_mcmc, burn_in = 2000, thin = 1, mu = c(0,0), Sigma = matrix(c(1,0.9,0.9,1), 2),amostra=50) {

  nome_do_dataframe <- deparse(substitute(resultado_mcmc))
  


  require(ggplot2)
  require(patchwork)
  require(mvtnorm)
  
  cadeia <- resultado_mcmc$cadeia_mk
  n_iter <- resultado_mcmc$n_iter
  tx_aceita <- resultado_mcmc$tx_aceita
  n_aceito <- resultado_mcmc$n_aceito
  
  cat("Taxa de aceitação:", round(tx_aceita, 4), "\n")
  cat("Número de amostras aceitas:", n_aceito, "\n")
  cat("Número total de iterações:", n_iter, "\n")
  
  # Descarte do burn-in e thinning
  cadeia_burnin <- cadeia[-seq_len(burn_in), , drop = FALSE]
  if (thin > 1) {
    cadeia_burnin <- cadeia_burnin[seq(1, nrow(cadeia_burnin), by = thin), , drop = FALSE]
  }
  
  df_cadeia <- as.data.frame(cadeia)
  colnames(df_cadeia) <- c("X1", "X2")
  df_cadeia$iter <- 1:nrow(df_cadeia)
  
  # Trace plots
  p1 <- ggplot(df_cadeia, aes(x = iter, y = X1)) +
    geom_line(color = "blue") +
    labs(title = "Trace plot para X1", 
    subtitle=paste("Dataframe utilizado:",nome_do_dataframe),x = "Iteração", y = "X1") +
    theme_minimal()
  
  p2 <- ggplot(df_cadeia, aes(x = iter, y = X2)) +
    geom_line(color = "darkgreen") +
    labs(title = "Trace plot para X2",
    subtitle=paste("Dataframe utilizado:",nome_do_dataframe), x = "Iteração", y = "X2") +
    theme_minimal()
  
  print(p1 / p2)
  
  # Scatter plot das amostras após burn-in
  df_cadeia_burnin <- as.data.frame(cadeia_burnin)
  colnames(df_cadeia_burnin) <- c("X1", "X2")
  
  amostras_teoricas <- mvtnorm::rmvnorm(nrow(df_cadeia_burnin), mean = mu, sigma = Sigma)
  df_teoricas <- as.data.frame(amostras_teoricas)
  colnames(df_teoricas) <- c("X1", "X2")
  
  # Scatter plot com contornos teóricos
  p_scatter <- ggplot(df_cadeia_burnin, aes(x = X1, y = X2)) +
    geom_point(alpha = 0.3, color = "purple", size = 1) +
    stat_density_2d(aes(fill = ..level..), geom = "polygon", alpha = 0.2, color = NA) +
    stat_density_2d(
      data = df_teoricas,
      aes(x = X1, y = X2),
      color = "red", size = 1, bins = 6, geom = "density_2d"
    ) +
    labs(title = "Scatter plot das amostras MCMC (após burn-in) com contornos teóricos",
         subtitle = paste("Dataframe utilizado:",nome_do_dataframe),
         x = "X1", y = "X2") +
    theme_minimal()
  print(p_scatter)
  
  
  # Autocorrelação
  acf_x1 <- acf(df_cadeia_burnin$X1, plot = FALSE)
  acf_x2 <- acf(df_cadeia_burnin$X2, plot = FALSE)
  par(mfrow = c(2, 1))
  plot(acf_x1, main = paste("Autocorrelação de X1 (após burn-in) | Dataframe:",nome_do_dataframe))
  plot(acf_x2, main = paste("Autocorrelação de X2 (após burn-in) | Dataframe:",nome_do_dataframe))
  par(mfrow = c(1, 1))
  
  # Amostragem sistemática para reduzir autocorrelação (thinning fixo de 50)
  cadeia_thin <- cadeia_burnin[seq(1, nrow(cadeia_burnin), by = amostra), , drop = FALSE]
  df_cadeia_thin <- as.data.frame(cadeia_thin)
  colnames(df_cadeia_thin) <- c("X1", "X2")
  df_cadeia_thin$iter <- 1:nrow(df_cadeia_thin)
  
  # Trace plots após thinning
  p1_thin <- ggplot(df_cadeia_thin, aes(x = iter, y = X1)) +
    geom_line(color = "blue") +
    labs(title = paste("Trace plot para X1 (amostrado a cada ",amostra,")"),
    subtitle = paste("Dataframe utilizado:",nome_do_dataframe), x = "Iteração", y = "X1") +
    theme_minimal()
  
  p2_thin <- ggplot(df_cadeia_thin, aes(x = iter, y = X2)) +
    geom_line(color = "darkgreen") +
    labs(title = paste("Trace plot para X2 (amostrado a cada ",amostra,")"), 
    subtitle = paste("Dataframe utilizado:",nome_do_dataframe),x = "Iteração", y = "X2") +
    theme_minimal()
  
  print(p1_thin / p2_thin)
  
  # Scatter plot e gráfico de nível após thinning
  amostras_teoricas2 <- mvtnorm::rmvnorm(nrow(df_cadeia_thin), mean = mu, sigma = Sigma)
  df_teoricas2 <- as.data.frame(amostras_teoricas2)
  colnames(df_teoricas2) <- c("X1", "X2")
  
  p_scatter_thin <- ggplot(df_cadeia_thin, aes(x = X1, y = X2)) +
    geom_point(alpha = 0.3, color = "purple", size = 1) +
    stat_density_2d(aes(fill = ..level..), geom = "polygon", alpha = 0.2, color = NA) +
    stat_density_2d(
      data = df_teoricas2,
      aes(x = X1, y = X2),
      color = "red", size = 1, bins = 6, geom = "density_2d"
    ) +
    labs(title = "Scatter plot das amostras MCMC (após thinning) com contornos teóricos",
         subtitle = paste("Avaliação da base de dados:",nome_do_dataframe),
         x = "X1", y = "X2") +
    theme_minimal()
  print(p_scatter_thin)
  
  
  invisible(list(
    cadeia_burnin = cadeia_burnin,
    cadeia_thin = cadeia_thin,
    taxa_aceitacao = tx_aceita,
    n_aceito = n_aceito,
    n_iter = n_iter
  ))
}

# Exemplo de uso:
 analisar_mcmc_com_thin(result_mcmc_sigma05,amostra=200)
```

Realizando a mesma análise para um $\sigma = 2$.

```{r prob3b_analysis3}

 analisar_mcmc_com_thin(result_mcmc_sigma2)

```

**Análise da Tarefa 3.2:**

De acordo com a tabela abaixo:

| Sigma                        | Taxa de aceitação |
|-------------------------------|------------------------|
| $\sigma=1$            |0,31|
| $\sigma=0.5$   |0,54|
| $\sigma=2$   |0,13|


Podemos observar que a simulação considerando um $\sigma=1$ aparentou possuir uma taxa de aceitação melhor que os demais. Uma taxa muito alta (caso do $\sigma=0.5$) significa que os passos da cadeia estão pequenos fazendo que a exploração fique muito lenta aumentando a autocorrelação (por isso que tive de aumentar a quantidade de passos na amostragem = 200). Por outro lado, uma taxa muito baixa, igual ao $\sigma=2$, mostra que está havendo passos muito altos na cadeia mostrando uma exploração ineficiente.

Observando os **trace plots** e **scatter plots** dos três valores de sigma, podemos concluir que:

1. **$\sigma = 1$** apresentou a **melhor convergência**:
   - Trace plots mostram boa mistura e exploração do espaço paramétrico
   - Scatter plot revela sobreposição adequada com os contornos teóricos da distribuição alvo
   - Autocorrelação moderada, permitindo boa exploração sem desperdício computacional

2. **$\sigma = 0.5$** mostrou **convergência mais lenta**:
   - Trace plots evidenciam movimento muito lento
   - Alta autocorrelação requer thinning maior (200 vs 50)
   - Exploração ineficiente do espaço, com a cadeia "presa" em regiões locais

3. **$\sigma = 2$** demonstrou **convergência irregular**:
   - Trace plots apresentam saltos muito grandes e rejeições frequentes
   - Scatter plot mostra pontos mais dispersos e menos aderência aos contornos teóricos
   - Exploração ineficiente por causa dos passos excessivamente grandes

**Conclusão Final:** O **$\sigma = 1$** é claramente superior, proporcionando o melhor equilíbrio entre eficiência de exploração, taxa de aceitação adequada e convergência rápida para a distribuição alvo Normal Bivariada com $\rho = 0.9$. 
