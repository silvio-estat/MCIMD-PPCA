---
title: "PPCA0026 - Tarefa 5: Métodos de Monte Carlo e MCMC"
subtitle: "Baseado em 'Statistical Computing with R' de Maria Rizzo"
author: "Sílvio Ferreira Gomes Júnior"
date: "2025-07-22"
format:
  html:
    embed-resources: true
    toc: true
    toc-depth: 3
    theme: cosmo
    code-fold: show
    code-tools: true
---

## Introdução

Este arquivo serve como seu template de resposta. Preencha as seções marcadas com seu código R, as saídas geradas, e suas análises textuais.

```{r setup, include=FALSE}
# Carregue todos os pacotes que você usará aqui
library(tidyverse)
library(mvtnorm) # Pode ser útil para o Problema 3
library(gridExtra) # Para arranjar múltiplos gráficos

# Configurações globais
knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  message = FALSE,
  fig.width = 8,
  fig.height = 6
)
```

---

## Problema 1: Integração por Monte Carlo e Variáveis Antitéticas (Capítulo 7)

Neste problema, vamos estimar o valor de uma integral definida e ver como uma técnica de amostragem mais inteligente pode melhorar a precisão da nossa estimativa.

**Tarefa (baseada no Exercício 7.5 de Rizzo):**

O nosso objetivo é estimar o valor de $I = \int_0^1 \frac{e^{-x}}{1+x^2} dx$.

### 1.1 Estimação com Monte Carlo Padrão

```{r prob1a_standard_mc}
# Defina a função a ser integrada
f <- function(x) {
  exp(-x) / (1 + x^2)
}

m <- 10000 # Número de amostras
set.seed(123)

# Gere as amostras e calcule a estimativa
u <- runif(m)  # Amostras uniformes em [0,1]
y <- f(u)      # Avaliações da função
estimate_mc <- mean(y)  # Estimativa Monte Carlo padrão
var_mc <- var(y) / m    # Variância da estimativa

# Reporte a estimativa e a variância empírica
cat("Monte Carlo Padrão:\n")
cat("Estimativa:", estimate_mc, "\n")
cat("Variância:", var_mc, "\n")
cat("Erro padrão:", sqrt(var_mc), "\n")
```

### 1.2 Estimação com Variáveis Antitéticas

```{r prob1b_antithetic_mc}
# Use m/2 amostras para criar m pontos de avaliação
set.seed(123)

# Gere as amostras e calcule a estimativa antitética
u1 <- runif(m/2)      # Primeira metade das amostras
u2 <- 1 - u1          # Variáveis antitéticas: 1-u1
y1 <- f(u1)           # Avaliações para u1
y2 <- f(u2)           # Avaliações para variáveis antitéticas
estimate_antithetic <- mean(c(y1, y2))  # Estimativa com variáveis antitéticas

# Calcular a variância da estimativa antitética
y_pairs <- (y1 + y2) / 2  # Média de cada par antitético
var_antithetic <- var(y_pairs) / (m/2)  # Variância da estimativa

# Reporte a estimativa e a variância empírica
cat("Variáveis Antitéticas:\n")
cat("Estimativa:", estimate_antithetic, "\n")
cat("Variância:", var_antithetic, "\n")
cat("Erro padrão:", sqrt(var_antithetic), "\n")
```

### 1.3 Análise e Comparação

```{r comparison_table}
# Criar tabela de comparação
results <- data.frame(
  Método = c("Monte Carlo Padrão", "Variáveis Antitéticas"),
  Estimativa = c(estimate_mc, estimate_antithetic),
  Variância = c(var_mc, var_antithetic),
  `Erro Padrão` = c(sqrt(var_mc), sqrt(var_antithetic))
)

# Calcular redução percentual na variância
reducao_variancia <- (var_mc - var_antithetic) / var_mc * 100

print(results)
cat("\nRedução na variância com variáveis antitéticas:", round(reducao_variancia, 2), "%\n")

# Valor teórico para comparação (calculado numericamente)
valor_teorico <- integrate(f, 0, 1)$value
cat("Valor teórico da integral:", valor_teorico, "\n")
```

**Análise:**

A técnica de variáveis antitéticas demonstrou uma melhoria substancial na eficiência da estimação Monte Carlo. Esta redução dramática na variância ocorre devido à correlação negativa induzida entre as variáveis U e 1-U. Quando a função integranda f(x) = e^(-x)/(1+x²) é monótona decrescente no intervalo [0,1], os valores f(U) e f(1-U) tendem a se compensar mutuamente, reduzindo significativamente a variabilidade da estimativa.

A estimativa das variáveis antitéticas está mais próxima do valor teórico comparada ao Monte Carlo padrão, demonstrando não apenas maior precisão (menor variância) mas também melhor acurácia. O erro padrão foi drasticamente reduzido, representando uma melhoria substancial na precisão da estimativa.

Esta técnica é particularmente efetiva para funções monótonas, onde a propriedade de compensação das variáveis antitéticas é maximizada, tornando-se uma ferramenta valiosa para melhorar a eficiência computacional em simulações Monte Carlo.

---

## Problema 2: Amostragem por Rejeição (Rejection Sampling) (Capítulo 6)

O objetivo é gerar amostras de uma distribuição `Beta(2, 2)` usando o algoritmo de amostragem por rejeição.

### 2.1 Encontrando a Constante `c`

```{r prob2a_find_c}
# A distribuição alvo é f(x) = dbeta(x, 2, 2)
# A distribuição envelope é g(x) = dunif(x, 0, 1) = 1
# Encontre o valor máximo da razão f(x)/g(x) no intervalo [0, 1].

# Para Beta(2,2), f(x) = 6x(1-x) para x em [0,1]
# A densidade uniforme g(x) = 1
# Então a razão é f(x)/g(x) = 6x(1-x)

# O máximo ocorre em x = 0.5 (derivada igual a zero)
# f'(x) = 6(1-2x) = 0 => x = 0.5

x_max <- 0.5
f_max <- dbeta(x_max, 2, 2)
c_value <- f_max / 1  # g(x) = 1

cat("Densidade Beta(2,2) em x = 0.5:", f_max, "\n")
cat("Valor da constante c:", c_value, "\n")

# Verificação gráfica
x_seq <- seq(0, 1, length.out = 1000)
ratio <- dbeta(x_seq, 2, 2) / 1
plot(x_seq, ratio, type = "l", main = "Razão f(x)/g(x)", 
     xlab = "x", ylab = "f(x)/g(x)")
abline(h = c_value, col = "red", lty = 2)
abline(v = x_max, col = "blue", lty = 2)
```

**Análise da Tarefa 2.1:**

O valor da constante **c = 1.5** foi determinado analiticamente através da maximização da razão f(x)/g(x). Para a distribuição Beta(2,2), a densidade é f(x) = 6x(1-x) para x ∈ [0,1], e usando a distribuição uniforme como envelope (g(x) = 1), a razão torna-se 6x(1-x).

A derivação f'(x) = 6(1-2x) = 0 confirma que o máximo ocorre em x = 0.5, onde f(0.5) = 1.5. Esta escolha de constante é ótima pois minimiza o número esperado de rejeições.

### 2.2 Implementando o Amostrador por Rejeição

```{r prob2b_rejection_sampler}
# Escreva uma função que implementa o algoritmo de amostragem por rejeição.
rejection_sampler_beta <- function(n, c) {
  samples <- numeric(n)
  n_proposals <- 0
  n_accepted <- 0
  
  while(n_accepted < n) {
    # Gerar proposta da distribuição envelope (uniforme)
    x <- runif(1, 0, 1)
    
    # Gerar u para teste de aceitação
    u <- runif(1, 0, 1)
    
    # Calcular a razão de densidades
    ratio <- dbeta(x, 2, 2) / (c * 1)  # g(x) = 1 para uniforme
    
    n_proposals <- n_proposals + 1
    
    # Teste de aceitação
    if(u <= ratio) {
      n_accepted <- n_accepted + 1
      samples[n_accepted] <- x
    }
  }
  
  acceptance_rate <- n_accepted / n_proposals
  
  return(list(
    samples = samples,
    acceptance_rate = acceptance_rate,
    n_proposals = n_proposals
  ))
}

# Gere 2000 amostras usando sua função
set.seed(123)
result <- rejection_sampler_beta(2000, c_value)
amostras_beta <- result$samples
cat("Taxa de aceitação:", result$acceptance_rate, "\n")
cat("Número total de propostas:", result$n_proposals, "\n")
```

### 2.3 Verificação dos Resultados

```{r prob2c_verification}
# Crie um histograma das suas amostras geradas
# Sobreponha a curva de densidade teórica da Beta(2, 2) para verificar
library(ggplot2)

# Criar dataframe para ggplot
df_samples <- data.frame(x = amostras_beta)

# Sequência para a densidade teórica
x_teorico <- seq(0, 1, length.out = 1000)
y_teorico <- dbeta(x_teorico, 2, 2)
df_teorico <- data.frame(x = x_teorico, y = y_teorico)

# Gráfico
p <- ggplot(df_samples, aes(x = x)) +
  geom_histogram(aes(y = after_stat(density)), bins = 30, 
                 fill = "lightblue", alpha = 0.7, color = "black") +
  geom_line(data = df_teorico, aes(x = x, y = y), 
            color = "red", linewidth = 1.5) +
  labs(title = "Histograma das Amostras vs Densidade Teórica Beta(2,2)",
       x = "x", y = "Densidade") +
  theme_minimal()

print(p)

# Reporte a taxa de aceitação do seu amostrador
cat("Taxa de aceitação teórica:", 1/c_value, "\n")
cat("Taxa de aceitação observada:", result$acceptance_rate, "\n")

# Teste Kolmogorov-Smirnov para verificar a distribuição
ks_test <- ks.test(amostras_beta, pbeta, 2, 2)
cat("Teste KS p-valor:", ks_test$p.value, "\n")
```

**Análise da Tarefa 2.3:**

**Análise do Desempenho:**
A proximidade entre as taxas de aceitação teórica (≈66.7%) e observada confirma a implementação correta do algoritmo. Uma taxa de aceitação de aproximadamente 67% é considerada muito eficiente para amostragem por rejeição, indicando que nossa escolha da distribuição envelope (uniforme) foi apropriada para a distribuição alvo Beta(2,2).

**Validação Estatística:**
O histograma das amostras geradas corresponde muito bem à densidade teórica da distribuição Beta(2,2), como evidenciado pela sobreposição da curva vermelha (densidade teórica) com o histograma. O teste de Kolmogorov-Smirnov não rejeita a hipótese nula de que as amostras seguem a distribuição Beta(2,2), confirmando estatisticamente a qualidade das amostras geradas.

A eficiência do método é evidenciada pela alta taxa de aceitação e pela correspondência visual entre o histograma empírico e a curva teórica, validando tanto a implementação quanto a escolha dos parâmetros do algoritmo.

---

## Problema 3: O Algoritmo de Metropolis-Hastings (Capítulo 9)

O objetivo é gerar amostras de uma distribuição Normal Bivariada com alta correlação ($\rho=0.9$) usando um amostrador de Metropolis-Hastings de passeio aleatório.

### 3.1 Implementando o Amostrador

```{r prob3a_metropolis_hastings}
# Defina a densidade alvo (ou seu logaritmo)
# A média é (0, 0) e a matriz de covariância tem 1s na diagonal e 0.9 fora dela.
library(mvtnorm)

# Matriz de covariância
Sigma <- matrix(c(1, 0.9, 0.9, 1), nrow = 2)
mu <- c(0, 0)

# Função de log-densidade (mais estável numericamente)
log_target <- function(x) {
  dmvnorm(x, mean = mu, sigma = Sigma, log = TRUE)
}

# Implemente a função do amostrador de Metropolis-Hastings
metropolis_bvn <- function(n_iter, sigma_prop) {
  # Inicializar a cadeia
  chain <- matrix(0, nrow = n_iter, ncol = 2)
  current_state <- c(0, 0)  # Estado inicial
  n_accepted <- 0
  
  # Matriz de covariância da proposta
  Sigma_prop <- diag(sigma_prop^2, 2)
  
  for(i in 1:n_iter) {
    # Propor um novo estado
    proposal <- rmvnorm(1, mean = current_state, sigma = Sigma_prop)[1,]
    
    # Calcular a razão de aceitação (em log-escala)
    log_alpha <- log_target(proposal) - log_target(current_state)
    alpha <- min(1, exp(log_alpha))
    
    # Aceitar ou rejeitar
    if(runif(1) < alpha) {
      current_state <- proposal
      n_accepted <- n_accepted + 1
    }
    
    # Armazenar o estado atual
    chain[i, ] <- current_state
  }
  
  acceptance_rate <- n_accepted / n_iter
  
  return(list(
    chain = chain,
    acceptance_rate = acceptance_rate
  ))
}

# Execute o amostrador
set.seed(123)
n_iter <- 10000
sigma_prop <- 1.0  # Ajuste este valor conforme necessário

result_mcmc <- metropolis_bvn(n_iter, sigma_prop)
cadeia_mcmc <- result_mcmc$chain
cat("Taxa de aceitação:", result_mcmc$acceptance_rate, "\n")
```

### 3.2 Análise da Saída

```{r prob3b_analysis}
# Descarte o burn-in
burn_in <- 2000
cadeia_final <- cadeia_mcmc[(burn_in+1):n_iter, ]

# Preparar dados para os gráficos
df_chain <- data.frame(
  iter = 1:n_iter,
  X1 = cadeia_mcmc[, 1],
  X2 = cadeia_mcmc[, 2]
)

df_final <- data.frame(
  X1 = cadeia_final[, 1],
  X2 = cadeia_final[, 2]
)

# Crie os trace plots para cada uma das duas variáveis
library(gridExtra)

p_trace1 <- ggplot(df_chain, aes(x = iter, y = X1)) +
  geom_line(alpha = 0.8, color = "steelblue") +
  geom_vline(xintercept = burn_in, color = "red", linetype = "dashed", linewidth = 1) +
  labs(title = "Trace Plot - X1", x = "Iteração", y = "X1") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

p_trace2 <- ggplot(df_chain, aes(x = iter, y = X2)) +
  geom_line(alpha = 0.8, color = "darkgreen") +
  geom_vline(xintercept = burn_in, color = "red", linetype = "dashed", linewidth = 1) +
  labs(title = "Trace Plot - X2", x = "Iteração", y = "X2") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

# Organizar verticalmente para melhor visualização das séries temporais
grid.arrange(p_trace1, p_trace2, nrow = 2)

# Crie o scatter plot das amostras geradas
p_scatter <- ggplot(df_final, aes(x = X1, y = X2)) +
  geom_point(alpha = 0.5, size = 0.8) +
  labs(title = "Scatter Plot das Amostras MCMC", x = "X1", y = "X2") +
  theme_minimal()

# Verificação Visual: Sobreponha as linhas de contorno teóricas
x_seq <- seq(-4, 4, length.out = 100)
y_seq <- seq(-4, 4, length.out = 100)
grid <- expand.grid(x = x_seq, y = y_seq)
grid$density <- dmvnorm(as.matrix(grid[, 1:2]), mean = mu, sigma = Sigma)

p_contour <- p_scatter +
  stat_contour(data = grid, aes(x = x, y = y, z = density), 
               color = "red", linewidth = 1) +
  labs(title = "Amostras MCMC com Contornos Teóricos")

print(p_contour)

# Reporte a taxa de aceitação
cat("Taxa de aceitação:", result_mcmc$acceptance_rate, "\n")

# Estatísticas descritivas
cat("Médias empíricas:\n")
cat("X1:", mean(cadeia_final[, 1]), "(teórica: 0)\n")
cat("X2:", mean(cadeia_final[, 2]), "(teórica: 0)\n")

cat("Variâncias empíricas:\n")
cat("X1:", var(cadeia_final[, 1]), "(teórica: 1)\n")
cat("X2:", var(cadeia_final[, 2]), "(teórica: 1)\n")

cat("Correlação empírica:", cor(cadeia_final[, 1], cadeia_final[, 2]), "(teórica: 0.9)\n")
```

**Análise da Tarefa 3.2:**

**Análise da Taxa de Aceitação:**
A taxa de aceitação observada está dentro da faixa aceitável para algoritmos de Metropolis-Hastings (20-50%), mas posiciona-se no limite desta faixa. Isso indica que o valor de σ_prop = 1.0 pode estar ligeiramente elevado, resultando em propostas que são rejeitadas com maior frequência do que o ideal.

**Convergência e Mistura:**
Os trace plots demonstram convergência adequada após o período de burn-in (2000 iterações). Ambas as variáveis apresentam boa mistura, oscilando adequadamente em torno dos valores esperados (zero) sem evidência de tendências sistemáticas ou períodos prolongados de estagnação.

**Qualidade das Amostras:**
As estatísticas empíricas (médias, variâncias e correlação) estão muito próximas dos valores teóricos, demonstrando que o amostrador reproduziu fielmente as características da distribuição alvo. A correlação empírica capturou precisamente a estrutura de dependência esperada.

**Análise da Distribuição Espacial:**
O scatter plot com contornos teóricos revela que o amostrador explorou corretamente a distribuição normal bivariada. As amostras exibem a característica forma elíptica esperada para uma distribuição com alta correlação positiva (ρ = 0.9), e a sobreposição dos contornos vermelhos confirma que a densidade empírica corresponde à distribuição teórica.

**Otimização da Eficiência:**
Embora os resultados sejam estatisticamente válidos, a eficiência poderia ser melhorada com valores de σ_prop entre 0.7-0.8, que provavelmente resultariam em taxas de aceitação mais próximas do ideal (40-45%). Para aplicações futuras, recomenda-se este ajuste para otimizar a eficiência computacional mantendo a qualidade das amostras geradas.

---

## Considerações Gerais

Os três métodos implementados demonstraram eficácia em seus respectivos contextos:

1. **Variáveis antitéticas** proporcionaram redução substancial de variância para integração Monte Carlo
2. **Amostragem por rejeição** mostrou alta eficiência com taxa de aceitação próxima de 70%
3. **Metropolis-Hastings** gerou amostras válidas da distribuição complexa, embora com espaço para otimização

Cada técnica ilustra diferentes aspectos dos métodos Monte Carlo: redução de variância, geração de amostras de distribuições específicas, e exploração de distribuições multivariadas complexas. Os resultados obtidos confirmam a validade teórica e prática destes métodos fundamentais em computação estatística.
